1. Передача данных с помощью всех типов отправки (Send, Ssend, Bsend, Rsen)
Напишите программу, в которой процессы с рангами 1, 2, 3 и 4 получают сообщение от процесса 0 с использованием различных способов передачи:
- Процесс 1 получает сообщение с помощью MPI_Send,
- Процесс 2 с использованием MPI_Ssend,
- Процесс 3 с использованием MPI_Bsend,
- Процесс 4 с использованием MPI_Rsend.
Каждый процесс должен измерять время получения сообщения с помощью MPI_Wtime и выводить результат. Процесс 0 должен отправить одинаковые данные всем четырём процессам и получить от них подтверждение приёма данных. 
Необходимо добавить обработку ошибок, если один из процессов не получил данные.

2. Передача данных переменной длины с использованием MPI_Probe и MPI_Get_count
Напишите программу, где процесс с рангом 0 отправляет массивы данных разного размера процессам 1, 2 и 3 с использованием MPI_Send. 
Процессы 1, 2 и 3 не знают заранее, сколько данных они получат, и должны использовать MPI_Probe, чтобы выяснить размер сообщения перед приёмом. 
Затем они принимают данные с помощью MPI_Recv и выполняют простую операцию (например, вычисление суммы элементов).
Каждый процесс возвращает результат процессу 0, который собирает и выводит результаты.
 
3. Параллельное умножение матрицы на вектор (матрицу) с использованием блокирующих операций
Напишите программу, в которой процесс 0 передает строки матрицы другим процессам для параллельного умножения на вектор. Используйте MPI_Send и MPI_Recv для передачи данных.
1. Процесс 0 содержит матрицу размером NxM и вектор длиной M.
2. Процесс 0 раздает строки матрицы процессам 1, 2 и т.д. для параллельного умножения.
3. Каждый процесс умножает свою строку матрицы на вектор и возвращает результат процессу 0.
4. Процесс 0 собирает результаты и выводит итоговый вектор.
Сравните время вычисления между последовательной и параллельной программой. Предоставьте аналитическое решение для сравнения корректности результатов.
4. Использование MPI_ANY_SOURCE и MPI_ANY_TAG

Реализуйте использование MPI_Recv с MPI_ANY_SOURCE и MPI_ANY_TAG в задачах выше.
5. Симуляция обмена сообщениями с взаимными блокировками и их устранение

Создайте программу, в которой процессы 1 и 2 обмениваются данными между собой с помощью MPI_Send и MPI_Recv. 
Нарочно создайте ситуацию взаимных блокировок (deadlock), когда процессы ожидают данных друг от друга, но не могут продолжить из-за блокировки.
После этого улучшите программу, чтобы избежать взаимных блокировок. Замерьте время выполнения программы до и после устранения deadlock с помощью MPI_Wtime и проанализируйте разницу.
 
Задание на 5 баллов.
 
Требования:
1. Все программы должны быть написаны на языке C++.
2. Реализуйте функции для каждого метода, чтобы основной код был чистым и легко модифицируемым.
3. Напишите комментарии к коду, объясняющие ключевые части алгоритма.
4. Предоставьте тесты на нескольких примерах с разной точностью.
5. Код должен быть представлен в виде текста, а не скриншотов и отправлен в личные сообщения тимс.
6. Сдача задания до следующего занятия, на котором будет проходить защита. Убедитесь, что каждый студент подготовил свой код и может объяснить реализацию и решение задачи.